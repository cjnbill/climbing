import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import os

# ================= ğŸ› ï¸ ç¨³å®šå¯¼å…¥ =================
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# ================= é¡µé¢é…ç½® =================
st.set_page_config(page_title="Climbing AI Coach Pro", page_icon="ğŸ§—", layout="wide")
st.title("ğŸ§— AI Climbing Coach (Stability & Force Analysis)")

# ================= ä¾§è¾¹æ è®¾ç½® =================
with st.sidebar:
    st.header("ğŸ”§ Settings")
    processing_speed = st.select_slider("Speed", options=["Standard", "Fast", "Turbo"], value="Fast")
    speed_map = {"Standard": 0, "Fast": 2, "Turbo": 4}
    frame_skip = speed_map[processing_speed]
    
    st.divider()
    st.header("âš–ï¸ Balance Analysis")
    show_balance = st.checkbox("Identify Redundant Limbs", value=True)
    flag_threshold = st.slider("Flagging Threshold", 130, 170, 150)

# ================= å‡ ä½•è®¡ç®—è¾…åŠ© =================
def point_in_triangle(p, a, b, c):
    """åˆ¤å®šç‚¹ P æ˜¯å¦åœ¨ä¸‰è§’å½¢ ABC å†…"""
    def sign(p1, p2, p3):
        return (p1[0] - p3[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p3[1])
    
    d1 = sign(p, a, b)
    d2 = sign(p, b, c)
    d3 = sign(p, c, a)
    has_neg = (d1 < 0) or (d2 < 0) or (d3 < 0)
    has_pos = (d1 > 0) or (d2 > 0) or (d3 > 0)
    return not (has_neg and has_pos)

# ================= æ ¸å¿ƒåˆ†æé€»è¾‘ =================
def process_video(input_path, output_path, skip_count):
    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
    cap = cv2.VideoCapture(input_path)
    
    orig_w, orig_h = int(cap.get(3)), int(cap.get(4))
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    target_h = 720
    scale = target_h / orig_h
    width, height = int(orig_w * scale), target_h

    fourcc = cv2.VideoWriter_fourcc(*'VP80') 
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    progress_bar = st.progress(0)
    
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        frame = cv2.resize(frame, (width, height))
        
        if frame_count % (skip_count + 1) != 0:
            out.write(frame)
            frame_count += 1
            continue

        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        if results.pose_landmarks:
            lm = results.pose_landmarks.landmark
            def get_pt(idx): return np.array([lm[idx].x * width, lm[idx].y * height])
            
            # è·å– 4 ä¸ªæœ«ç«¯ç‚¹
            limbs = {
                "L-Hand": get_pt(15), "R-Hand": get_pt(16),
                "L-Foot": get_pt(27), "R-Foot": get_pt(28)
            }
            # è·å–é‡å¿ƒ (Hip Center)
            hip_c = (get_pt(23) + get_pt(24)) / 2

            # --- å—åŠ›/å¹³è¡¡åˆ†æ ---
            if show_balance:
                names = list(limbs.keys())
                redundant_limb = None
                
                # å°è¯•å»æ‰æ¯ä¸€ä¸ªè‚¢ä½“ï¼Œæ£€æŸ¥é‡å¿ƒæ˜¯å¦ä»åœ¨å‰©ä½™ä¸‰ä¸ªæ„æˆçš„ä¸‰è§’å½¢å†…
                for i in range(4):
                    others = [limbs[names[j]] for j in range(4) if i != j]
                    if point_in_triangle(hip_c, others[0], others[1], others[2]):
                        redundant_limb = names[i]
                        break # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå†—ä½™ç‚¹å°±è·³å‡º
                
                # è§†è§‰æ ‡è®°
                for name, pt in limbs.items():
                    color = (0, 0, 255) if name == redundant_limb else (0, 255, 0)
                    size = 5 if name == redundant_limb else 10
                    cv2.circle(image, (int(pt[0]), int(pt[1])), size, color, -1)
                    if name == redundant_limb:
                        cv2.putText(image, "REDUNDANT", (int(pt[0]), int(pt[1])-20), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            # ç»˜åˆ¶é‡å¿ƒæŠ•å½±
            cv2.circle(image, (int(hip_c[0]), int(hip_c[1])), 8, (255, 255, 255), 2)
            
            # ç»˜åˆ¶éª¨æ¶
            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        out.write(image)
        frame_count += 1
        if frame_count % 15 == 0: progress_bar.progress(min(frame_count/total_frames, 1.0))

    cap.release()
    out.release()
    return output_path

# ================= UI å¸ƒå±€ =================
col1, col2 = st.columns([1, 1])
with col1:
    st.subheader("1. Source Video")
    if 'processed_video' in st.session_state:
        if st.button("ğŸ”„ Analyze New Video"):
            st.session_state.clear()
            st.rerun()
    uploaded_file = st.file_uploader("Upload", type=['mov', 'mp4'])

if uploaded_file:
    if 'original_video' not in st.session_state:
        t = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1])
        t.write(uploaded_file.read())
        st.session_state['original_video'] = t.name
    
    with col1:
        st.video(st.session_state['original_video'])
        if 'processed_video' not in st.session_state:
            if st.button("Run Balance Analysis âš–ï¸", type="primary"):
                out_name = tempfile.NamedTemporaryFile(delete=False, suffix='.webm').name
                with col2:
                    with st.spinner('Calculating Support Polygon...'):
                        res = process_video(st.session_state['original_video'], out_name, frame_skip)
                    if res and os.path.getsize(res) > 0:
                        st.session_state['processed_video'] = res
                        st.rerun()

if 'processed_video' in st.session_state:
    with col2:
        st.subheader("2. Stability Insights")
        res_file = st.session_state['processed_video']
        with open(res_file, 'rb') as f: st.video(f.read(), format="video/webm")
        st.info("ğŸ”´ Red circles mark 'Redundant' limbs. Your COG is stable without them.")
