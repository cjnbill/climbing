import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile
import os

# ================= ğŸ› ï¸ ç¨³å®šå¯¼å…¥ =================
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# ================= é¡µé¢é…ç½® =================
st.set_page_config(page_title="Climbing AI Coach", page_icon="ğŸ§—", layout="wide")
st.title("ğŸ§— AI Climbing Coach (High Performance)")

# ================= ä¾§è¾¹æ è®¾ç½® =================
with st.sidebar:
    st.header("ğŸ”§ Performance Settings")
    
    # æ ¸å¿ƒåŠ é€Ÿå¼€å…³ï¼šè·³å¸§å¤„ç†
    # Standard: é€å¸§åˆ†æ (æ…¢)
    # Fast: æ¯ 3 å¸§åˆ†æ 1 å¸§ (æ¨è)
    # Turbo: æ¯ 5 å¸§åˆ†æ 1 å¸§ (æå¿«)
    processing_speed = st.select_slider(
        "Processing Speed (Frame Skipping)",
        options=["Standard", "Fast", "Turbo"],
        value="Fast"
    )
    speed_map = {"Standard": 0, "Fast": 2, "Turbo": 4}
    frame_skip = speed_map[processing_speed]
    
    st.divider()
    st.header("ğŸ§— Coaching Settings")
    flag_threshold = st.slider("Flagging Angle Threshold", 130, 170, 150)
    show_skeleton = st.checkbox("Show Skeleton", value=True)
    show_trail = st.checkbox("Show Hip Trajectory", value=True)

# ================= æ ¸å¿ƒåˆ†æé€»è¾‘ =================
def process_video(input_path, output_path, skip_count):
    # ä½¿ç”¨é»˜è®¤æ¨¡å‹å¤æ‚åº¦ (ä¸ä½¿ç”¨ Lite)ï¼Œå¹³è¡¡ç²¾åº¦ä¸ç¨³å®šæ€§
    pose = mp_pose.Pose(
        min_detection_confidence=0.5, 
        min_tracking_confidence=0.5
    )
    
    cap = cv2.VideoCapture(input_path)
    # è·å–åŸå§‹è§†é¢‘å‚æ•°
    orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    
    # ç­–ç•¥ï¼šå¦‚æœè§†é¢‘åˆ†è¾¨ç‡è¿‡é«˜ï¼ˆå¦‚ 4K/1080Pï¼‰ï¼Œå°†å…¶ç­‰æ¯”ä¾‹ç¼©æ”¾åˆ° 720p è¿›è¡Œå¤„ç†
    # è¿™èƒ½æ˜¾è‘—å‡å°‘ CPU è´Ÿæ‹…ï¼Œè€Œä¸æŸå¤± AI è¯†åˆ«ç‡
    target_h = 720
    if orig_h > target_h:
        scale = target_h / orig_h
        width = int(orig_w * scale)
        height = target_h
    else:
        width, height = orig_w, orig_h

    # ä½¿ç”¨ VP80 ç¼–ç ç”Ÿæˆ WebM æ–‡ä»¶
    fourcc = cv2.VideoWriter_fourcc(*'VP80') 
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    hip_trail = []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    progress_bar = st.progress(0)
    
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        # å°ºå¯¸é¢„å¤„ç†
        if orig_h > target_h:
            frame = cv2.resize(frame, (width, height))

        # --- æ€§èƒ½ä¼˜åŒ–ï¼šè·³å¸§åˆ¤æ–­ ---
        # å¦‚æœä¸æ˜¯ç›®æ ‡å¸§ï¼Œåˆ™è·³è¿‡ AI è®¡ç®—ï¼Œç›´æ¥å†™å…¥åŸå§‹ç”»é¢
        if frame_count % (skip_count + 1) != 0:
            out.write(frame)
            frame_count += 1
            continue

        # --- AI è®¡ç®—éƒ¨åˆ† ---
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        if results.pose_landmarks:
            lm = results.pose_landmarks.landmark
            def get_pt(idx): return [lm[idx].x * width, lm[idx].y * height]
            
            # è½¨è¿¹è¿½è¸ª
            if show_trail:
                hip = get_pt(23)
                hip_trail.append((int(hip[0]), int(hip[1])))
                if len(hip_trail) > 50: hip_trail.pop(0)
                for i in range(1, len(hip_trail)):
                    cv2.line(image, hip_trail[i-1], hip_trail[i], (0, 255, 255), 2)

            # Flagging åˆ¤å®šé€»è¾‘
            l_h, l_k, l_a = get_pt(23), get_pt(25), get_pt(27)
            r_h, r_k, r_a = get_pt(24), get_pt(26), get_pt(28)
            
            def check_ang(a, b, c):
                a, b, c = np.array(a), np.array(b), np.array(c)
                rad = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
                ang = np.abs(rad*180.0/np.pi)
                return 360-ang if ang > 180 else ang

            if check_ang(l_h, l_k, l_a) > flag_threshold or check_ang(r_h, r_k, r_a) > flag_threshold:
                cv2.putText(image, "NICE FLAG!", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)

            # éª¨æ¶ç»˜åˆ¶
            if show_skeleton:
                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        out.write(image)
        frame_count += 1
        
        # æ¯ 10 å¸§æ›´æ–°ä¸€æ¬¡è¿›åº¦æ¡ï¼ŒèŠ‚çœ UI åˆ·æ–°å¼€é”€
        if frame_count % 10 == 0:
            progress_bar.progress(min(frame_count/total_frames, 1.0))

    cap.release()
    out.release()
    progress_bar.empty()
    return output_path

# ================= UI å¸ƒå±€ (Session State) =================
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("1. Source Video")
    if 'processed_video' in st.session_state:
        if st.button("ğŸ”„ Analyze New Video"):
            st.session_state.clear()
            st.rerun()

    uploaded_file = st.file_uploader("Upload Climbing Video (MOV/MP4)", type=['mov', 'mp4'])

if uploaded_file:
    if 'original_video' not in st.session_state:
        t = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(
